{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Classification / tc-reuter.ipynb\n",
    "# Gourav Siddhad\n",
    "# 07-Mar-2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Importing Libraries', end='')\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "import sklearn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import string\n",
    "import csv\n",
    "import os\n",
    "import itertools\n",
    "import tarfile\n",
    "import re\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "print(' - Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('reuters-data'):\n",
    "    os.mkdir('reuters-data')\n",
    "\n",
    "# Decompress data\n",
    "# compressed = tarfile.open('reuters-data/reuters21578.tar.gz')\n",
    "# compressed.extractall(path = 'reuters-data/')\n",
    "# compressed.close()\n",
    "\n",
    "# List the uncompressed data\n",
    "print('Directory Listing')\n",
    "os.listdir('reuters-data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in each data file\n",
    "text_data = []\n",
    "\n",
    "print('Loading Files - ', end=' ')\n",
    "for index in range(22):\n",
    "    if index is not 17:\n",
    "        print(index, end=' ')\n",
    "        filename = 'reuters-data/reut2-{0}.sgm'.format(str(index).zfill(3))\n",
    "        with open(filename, 'r', encoding = 'utf-8', errors = 'ignore') as infile:\n",
    "            text_data.append(infile.read())\n",
    "\n",
    "print()\n",
    "print('Loading Files - Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Separate each text file into articles\n",
    "\n",
    "print('Converting Files to Articles - ', end='')\n",
    "i, counter = 0, 0\n",
    "\n",
    "columns = ['Title', 'Topics', 'Text']\n",
    "index = [x for x in range(0, 18103)]\n",
    "df = pd.DataFrame(columns=columns, index=index)\n",
    "\n",
    "for textfile in text_data:\n",
    "    print(i, end=' ')\n",
    "    # Parse text as html\n",
    "    soup = BeautifulSoup(textfile, 'html.parser')\n",
    "    \n",
    "    # Extract article between <BODY> and </BODY> and convert to standard text. Add to list of articles\n",
    "    title = soup.find('reuters')['lewissplit']\n",
    "    topics = soup.find_all('topics')\n",
    "    \n",
    "    j=0\n",
    "    for article in soup.find_all('body'):\n",
    "        df['Text'][counter] = article.get_text()\n",
    "        df['Title'][counter] = title\n",
    "        df['Topics'][counter] = topics[j].find_all('d')\n",
    "        j += 1\n",
    "        counter += 1\n",
    "    \n",
    "    i += 1\n",
    "\n",
    "print()\n",
    "print('Files to Aritcle Conversion - Done')\n",
    "print('Total Articles - ', counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for topic in df['Topics']:\n",
    "    if len(topic)>0:\n",
    "        count += 1\n",
    "print('Documents with Complete Details - ', count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
