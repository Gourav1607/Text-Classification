{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text Classification / tc-nltk-lsa-rf.ipynb\n",
    "# Gourav Siddhad\n",
    "# 05-Mar-2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Importing Libraries', end='')\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import reuters\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer, StandardScaler, Normalizer\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "print(' - Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = reuters.fileids()\n",
    "print('Total Documents -', len(documents))\n",
    "\n",
    "print('Extracting (Id, Docs and Labels)', end='')\n",
    "train_docs_id = list(filter(lambda doc: doc.startswith(\"train\"), documents))\n",
    "test_docs_id = list(filter(lambda doc: doc.startswith(\"test\"), documents))\n",
    "\n",
    "train_docs = [reuters.raw(doc_id) for doc_id in train_docs_id]\n",
    "test_docs = [reuters.raw(doc_id) for doc_id in test_docs_id]\n",
    "all_docs = train_docs\n",
    "all_docs += test_docs\n",
    "\n",
    "train_labels = [reuters.categories(doc_id) for doc_id in train_docs_id]\n",
    "test_labels  = [reuters.categories(doc_id) for doc_id in test_docs_id]\n",
    "all_labels = train_labels\n",
    "all_labels += test_labels\n",
    "print(' - Done')\n",
    "\n",
    "del train_docs\n",
    "del test_docs\n",
    "del train_labels\n",
    "del test_labels\n",
    "\n",
    "print('Documents - ', len(all_docs))\n",
    "print('Labels  - ', len(all_labels))\n",
    "\n",
    "# List of categories\n",
    "categories = reuters.categories()\n",
    "print('Categories - ', len(categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Caching Stop Words', end='')\n",
    "cachedStopWords = stopwords.words(\"english\")\n",
    "print(' - Done')\n",
    "\n",
    "def tokenize(text):\n",
    "    min_length = 3\n",
    "    words = map(lambda word: word.lower(), word_tokenize(text))\n",
    "    words = [word for word in words if word not in cachedStopWords]\n",
    "    tokens =(list(map(lambda token: PorterStemmer().stem(token), words)))\n",
    "    p = re.compile('[a-zA-Z]+')\n",
    "    filtered_tokens = list(filter(lambda token: p.match(token) and len(token)>=min_length, tokens))\n",
    "    return filtered_tokens\n",
    "\n",
    "def feature_values(doc, representer):\n",
    "    doc_representation = representer.transform([doc])\n",
    "    features = representer.get_feature_names()\n",
    "    return [(features[index], doc_representation[0, index]) for index in doc_representation.nonzero()[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Sorting Train:Test Docs', end='')\n",
    "X_train, X_test, y_train, y_test = train_test_split(all_docs, all_labels, test_size=0.2, random_state=42)\n",
    "print(' - Done')\n",
    "\n",
    "print('Creating TF-IDF (Train)', end='')\n",
    "tfidf = TfidfVectorizer(tokenizer=tokenize, use_idf=True, sublinear_tf=True, norm='l2')\n",
    "train_features = tfidf.fit_transform(X_train)\n",
    "print(' - Done')\n",
    "\n",
    "print('Creating TF-IDF (Test)', end='')\n",
    "test_features = tfidf.transform(X_test)\n",
    "print(' - Done')\n",
    "\n",
    "print('Binarizing MultiLabels', end='')\n",
    "lb = MultiLabelBinarizer()\n",
    "y_train = lb.fit_transform(y_train)\n",
    "y_test = lb.transform(y_test)\n",
    "print(' - Done')\n",
    "\n",
    "del all_docs\n",
    "del all_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Semantic Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lsa_svd(comp=5000):\n",
    "    svd = TruncatedSVD(n_components=comp)\n",
    "    lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "\n",
    "    lsa.fit(train_features)\n",
    "    train_lsa = lsa.transform(train_features)\n",
    "    test_lsa = lsa.transform(test_features)\n",
    "\n",
    "    return (sum(svd.explained_variance_ratio_), train_lsa, test_lsa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training & Testing Random Forest')\n",
    "print('Iterations - ', end='')\n",
    "\n",
    "variance_rf, acc_rf, train_time_rf, test_time_rf = [], [], [], []\n",
    "index = []\n",
    "maxn, step = 200, 1\n",
    "\n",
    "i = step\n",
    "while i <= maxn:\n",
    "    print(i, end='')\n",
    "    index.append(i)\n",
    "    (variance, train_lsa, test_lsa) = lsa_svd(i)\n",
    "    \n",
    "    model_rf = RandomForestClassifier(n_estimators=i)\n",
    "    start = time.time()\n",
    "    model_rf.fit(train_lsa, y_train)\n",
    "    end = time.time()\n",
    "    \n",
    "    train_time_rf.append(end-start)\n",
    "    print('.', end=' ')\n",
    "    \n",
    "    start = time.time()\n",
    "    y_pred = model_rf.predict(test_lsa)\n",
    "    end = time.time()\n",
    "\n",
    "    test_time_rf.append(end-start)\n",
    "    acc_rf.append(accuracy_score(y_test, y_pred))\n",
    "    variance_rf.append(variance)\n",
    "        \n",
    "    i += step\n",
    "    \n",
    "    del model_rf\n",
    "    del start\n",
    "    del end\n",
    "    del y_pred\n",
    "    del variance\n",
    "    del train_lsa\n",
    "    del test_lsa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Creating Result DataFrame', end=' ')\n",
    "columns=['Variance', 'Accuracy', 'Train Time', 'Test Time']\n",
    "df_rf = pd.DataFrame(columns=columns, index=index)\n",
    "\n",
    "df_rf['Variance'] = variance_rf\n",
    "df_rf['Accuracy'] = acc_rf\n",
    "df_rf['Train Time'] = train_time_rf\n",
    "df_rf['Test Time'] = test_time_rf\n",
    "\n",
    "print(' - Done')\n",
    "\n",
    "print()\n",
    "print(df_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Extracted Data Shape ')\n",
    "print('Train : ', train_features.shape)\n",
    "print('Test  : ', test_features.shape)\n",
    "print()\n",
    "plt.plot(index, acc_rf, label='Accuracy')\n",
    "plt.legend(loc=4)\n",
    "plt.title('Accuracy')\n",
    "plt.savefig('tc-nltk-lsa-rf.png', dpi=150, pad_inches=0.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datetime.now())\n",
    "\n",
    "print('Writing to CSV', end='')\n",
    "df_rf.to_csv('tc-nltk-lsa-rf.csv', header=True)\n",
    "print(' - Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxa, mindex = 0, 0 \n",
    "i = step\n",
    "while i<=maxn:\n",
    "    if df_rf['Accuracy'][i] > maxa:\n",
    "        maxa = df_rf['Accuracy'][i]\n",
    "        mindex = i\n",
    "    i += step\n",
    "    \n",
    "print('Max - ', maxa)\n",
    "print('Index - ', mindex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Testing and Results on Best Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training Random Forest', end='')\n",
    "\n",
    "# Max -  0.726598702502317\n",
    "# Index -  37\n",
    "# mindex = 37\n",
    "\n",
    "(variance, train_lsa, test_lsa) = lsa_svd(mindex)\n",
    "model_rf = RandomForestClassifier(n_estimators=i)  # Use optimum values\n",
    "\n",
    "start = time.time()\n",
    "model_rf.fit(train_lsa, y_train)\n",
    "end = time.time()\n",
    "print(' - Done')\n",
    "\n",
    "train_time_rf = end-start\n",
    "\n",
    "print('Testing Random Forest', end='')\n",
    "start = time.time()\n",
    "y_pred = model_rf.predict(test_lsa)\n",
    "end = time.time()\n",
    "print(' - Done')\n",
    "\n",
    "test_time_rf = end-start\n",
    "acc_rf = accuracy_score(y_test, y_pred)\n",
    "cmat_rf = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(title, test_y, pred_y):\n",
    "    print('ROC for : ', title)\n",
    "    # Compute ROC curve and ROC area for each class\n",
    "    fpr = dict()\n",
    "    tpr = dict()\n",
    "    roc_auc = dict()\n",
    "    n_class = test_y.shape[1]\n",
    "    for i in range(n_class):\n",
    "        fpr[i], tpr[i], _ = roc_curve(test_y[:, i], pred_y[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "    # Compute micro-average ROC curve and ROC area\n",
    "    fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(test_y.ravel(), pred_y.ravel())\n",
    "    roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "    # Compute macro-average ROC curve and ROC area\n",
    "\n",
    "    # Aggregate all false positive rates\n",
    "    all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_class)]))\n",
    "\n",
    "    # Interpolate all ROC curves\n",
    "    mean_tpr = np.zeros_like(all_fpr)\n",
    "    for i in range(n_class):\n",
    "        mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "    # Average it and compute AUC\n",
    "    mean_tpr /= n_class\n",
    "\n",
    "    fpr[\"macro\"] = all_fpr\n",
    "    tpr[\"macro\"] = mean_tpr\n",
    "    roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "    # Plot all ROC curves\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 10))\n",
    "    ax1.plot(fpr[\"micro\"], tpr[\"micro\"], label='micro-avg ROC (area = {0:0.2f})'.format(roc_auc[\"micro\"]), color='deeppink')\n",
    "    ax1.plot(fpr[\"macro\"], tpr[\"macro\"], label='macro-avg ROC (area = {0:0.2f})'.format(roc_auc[\"macro\"]), color='navy')\n",
    "    ax1.plot([0, 1], [0, 1], 'k--')\n",
    "    ax1.set_xlabel('False Positive Rate')\n",
    "    ax1.set_ylabel('True Positive Rate')\n",
    "    ax1.set_title('ROC multi-class')\n",
    "    ax1.legend(loc=\"lower right\")\n",
    "\n",
    "    colors = cycle(['aqua', 'darkorange', 'cornflowerblue'])\n",
    "    for i, color in zip(range(n_class), colors):\n",
    "        ax2.plot(fpr[i], tpr[i], color=color, label='ROC curve of class {0} (area = {1:0.2f})'.format(i, roc_auc[i]))\n",
    "    ax2.set_title('ROC Individual Classes')\n",
    "    ax2.set_xlabel('False Positive Rate')\n",
    "    ax2.set_ylabel('True Positive Rate')\n",
    "    ax2.set_title('ROC multi-class')\n",
    "    plt.savefig(title+'.png', dpi=300, pad_inches=0.1)\n",
    "    plt.show()\n",
    "    \n",
    "    return (roc_auc)\n",
    "\n",
    "roc_auc_rf = plot_roc('tc-nltk-lsa-rf-accurate', y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Original Data Shape ')\n",
    "print('Train : ', train_features.shape)\n",
    "print('Test  : ', test_features.shape)\n",
    "print('Reduced Data Shape ')\n",
    "print('Train : ', train_lsa.shape)\n",
    "print('Test  : ', test_lsa.shape)\n",
    "print()\n",
    "print('Accuracy :', acc_rf * 100)\n",
    "print('Time Taken - Train : {0:.4f}, Test : {1:.4f}'.format(train_time_rf, test_time_rf))\n",
    "print('Area under ROC : {0:7.4f}'.format(roc_auc_rf['micro']*100))\n",
    "print()\n",
    "print('Confusion Matrix')\n",
    "print(cmat_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
